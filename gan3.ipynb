{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Reshape, Flatten\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"reshape_5\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [16, 16, 131072], output_shape = [32, 32, 128]\n\nCall arguments received by layer \"reshape_5\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 16, 16, 131072), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m generator\u001b[39m.\u001b[39madd(Dense(\u001b[39m128\u001b[39m \u001b[39m*\u001b[39m \u001b[39m32\u001b[39m \u001b[39m*\u001b[39m \u001b[39m32\u001b[39m))\n\u001b[0;32m     32\u001b[0m generator\u001b[39m.\u001b[39madd(LeakyReLU(\u001b[39m0.2\u001b[39m))\n\u001b[1;32m---> 33\u001b[0m generator\u001b[39m.\u001b[39;49madd(Reshape((\u001b[39m32\u001b[39;49m, \u001b[39m32\u001b[39;49m, \u001b[39m128\u001b[39;49m)))\n\u001b[0;32m     34\u001b[0m generator\u001b[39m.\u001b[39madd(BatchNormalization())\n\u001b[0;32m     35\u001b[0m generator\u001b[39m.\u001b[39madd(Conv2DTranspose(\u001b[39m64\u001b[39m, (\u001b[39m5\u001b[39m, \u001b[39m5\u001b[39m), strides\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msame\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\keras\\src\\layers\\reshaping\\reshape.py:118\u001b[0m, in \u001b[0;36mReshape._fix_unknown_dimension\u001b[1;34m(self, input_shape, output_shape)\u001b[0m\n\u001b[0;32m    116\u001b[0m     output_shape[unknown] \u001b[39m=\u001b[39m original \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m known\n\u001b[0;32m    117\u001b[0m \u001b[39melif\u001b[39;00m original \u001b[39m!=\u001b[39m known:\n\u001b[1;32m--> 118\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    119\u001b[0m \u001b[39mreturn\u001b[39;00m output_shape\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"reshape_5\" (type Reshape).\n\ntotal size of new array must be unchanged, input_shape = [16, 16, 131072], output_shape = [32, 32, 128]\n\nCall arguments received by layer \"reshape_5\" (type Reshape):\n  • inputs=tf.Tensor(shape=(None, 16, 16, 131072), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# Define your dataset directory\n",
    "dataset_dir = 'C:\\\\Users\\\\Rishikeshs\\\\Downloads\\\\Cat'\n",
    "\n",
    "# Define parameters\n",
    "img_width, img_height, channels = 28, 28, 3  # Adjust these dimensions to match your images\n",
    "latent_dim = 100  # Size of the random noise vector\n",
    "batch_size = 128\n",
    "epochs = 200\n",
    "save_interval = 100  # Save generated images every 'save_interval' epochs\n",
    "\n",
    "# Create a data generator for loading and augmenting images\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,  # Normalize pixel values to [0, 1]\n",
    "    horizontal_flip=True  # Data augmentation: flip images horizontally\n",
    ")\n",
    "\n",
    "# Load and preprocess images from your dataset using the data generator\n",
    "data_generator = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None  # We don't need class labels for a GAN\n",
    ")\n",
    "\n",
    "# Build the generator network\n",
    "generator = Sequential()\n",
    "generator.add(Dense(128 * 16 * 16, input_dim=latent_dim))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Reshape((16, 16, 128)))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Dense(128 * 32 * 32))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Reshape((32, 32, 128)))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same'))\n",
    "generator.add(LeakyReLU(0.2))\n",
    "generator.add(Conv2DTranspose(channels, (5, 5), strides=(2, 2), padding='same', activation='sigmoid'))\n",
    "\n",
    "# Build the discriminator network\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=(img_width, img_height, channels)))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "discriminator.add(LeakyReLU(0.2))\n",
    "discriminator.add(Flatten())\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the discriminator\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "\n",
    "# Build the GAN model by combining the generator and discriminator\n",
    "discriminator.trainable = False  # Freeze the discriminator during GAN training\n",
    "gan_input = Input(shape=(latent_dim,))\n",
    "x = generator(gan_input)\n",
    "gan_output = discriminator(x)\n",
    "gan = Model(gan_input, gan_output)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    for _ in range(data_generator.samples // batch_size):\n",
    "        # Train discriminator on real images\n",
    "        real_images = next(data_generator)\n",
    "        real_labels = np.ones((batch_size, 1))\n",
    "        d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "\n",
    "        # Train discriminator on generated (fake) images\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        fake_images = generator.predict(noise)\n",
    "        fake_labels = np.zeros((batch_size, 1))\n",
    "        d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
    "\n",
    "        # Train generator to fool the discriminator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        valid_labels = np.ones((batch_size, 1))\n",
    "        g_loss = gan.train_on_batch(noise, valid_labels)\n",
    "\n",
    "    # Print progress and save generated images\n",
    "    if epoch % save_interval == 0:\n",
    "        print(f\"Epoch {epoch}, D Loss Real: {d_loss_real[0]}, D Loss Fake: {d_loss_fake[0]}, G Loss: {g_loss}\")\n",
    "        save_generated_images(epoch)\n",
    "\n",
    "# Function to save generated images\n",
    "def save_generated_images(epoch, examples=10, dim=(1, 10), figsize=(10, 1)):\n",
    "    noise = np.random.normal(0, 1, (examples, latent_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = 0.5 * generated_images + 0.5  # Rescale to [0, 1]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(examples):\n",
    "        plt.subplot(dim[0], dim[1], i + 1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'gan_generated_image_epoch_{epoch}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
